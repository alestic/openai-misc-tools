#!/usr/bin/env python3
"""
NAME
    openai-token-count - counts the number of tokens in text files
    according to a specified OpenAI model

SYNOPSIS
    openai-token-count [options] file...

DESCRIPTION
    openai-token-count reads the specified text files and computes the
    number of tokens for each file as per the OpenAI model's
    specifications.

    If no file is specified, or if the file is -, openai-token-count
    reads from standard input.

    The number of tokens and file name are then printed to standard
    output.

OPTIONS
    --model MODEL_NAME
        Specifies the OpenAI model to use for counting
        tokens. Defaults to "gpt-4-0314".
    
    file
        The text file to count tokens in. Multiple files can be
        specified. If no file is provided or if the file is '-',
        openai-token-count reads from standard input.

EXAMPLES
    Count tokens in a single file:
    ./openai-token-count example.txt

    Count tokens in multiple files:
    ./openai-token-count file1.txt file2.txt

    Count tokens in standard input:
    cat example.txt | ./openai-token-count

    Count tokens using a different model:
    ./openai-token-count --model "gpt-3.5-turbo-0301" example.txt

AUTHORS
    Written by GPT-4.
    Prompt engineering by Eric Hammond.
    Some code Copyright (c) 2023 OpenAI

DATE
    2023-06-20
"""

import argparse
import sys
import tiktoken

# Constants
#DEFAULT_MODEL = "gpt-4-0613"
DEFAULT_MODEL = "gpt-4-0314"

# The function num_tokens_from_messages is copied from the OpenAI cookbook: 
# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb
def num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301"):
    """Returns the number of tokens used by a list of messages."""
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        print("Warning: model not found. Using cl100k_base encoding.")
        encoding = tiktoken.get_encoding("cl100k_base")
    if model == "gpt-3.5-turbo":
        print("Warning: gpt-3.5-turbo may change over time. Returning num tokens assuming gpt-3.5-turbo-0301.")
        return num_tokens_from_messages(messages, model="gpt-3.5-turbo-0301")
    elif model == "gpt-4":
        print("Warning: gpt-4 may change over time. Returning num tokens assuming gpt-4-0314.")
        return num_tokens_from_messages(messages, model="gpt-4-0314")
    elif model == "gpt-3.5-turbo-0301":
        tokens_per_message = 4  # every message follows <|start|>{role/name}\n{content}<|end|>\n
        tokens_per_name = -1  # if there's a name, the role is omitted
    elif model == "gpt-4-0314":
        tokens_per_message = 3
        tokens_per_name = 1
    else:
        raise NotImplementedError(f"""num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.""")
    num_tokens = 0
    for message in messages:
        num_tokens += tokens_per_message
        for key, value in message.items():
            num_tokens += len(encoding.encode(value))
            if key == "name":
                num_tokens += tokens_per_name
    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>
    return num_tokens

def count_tokens_in_file(file, model):
    text = file.read()
    # Here we assume the text from each file is a single message
    message = [{"role": "user", "content": text.strip()}]
    num_tokens = num_tokens_from_messages(message, model)
    print(f"{num_tokens} {file.name}")

def main():
    parser = argparse.ArgumentParser(description='Counts the number of tokens in the given files.')
    parser.add_argument('files', metavar='F', type=argparse.FileType('r'), nargs='*',
                        help='a file for token counting',
                        default=[sys.stdin])
    parser.add_argument('--model', default=DEFAULT_MODEL,
                        help='the OpenAI model to use (default: {})'.format(DEFAULT_MODEL))
    args = parser.parse_args()

    for file in args.files:
        count_tokens_in_file(file, args.model)

if __name__ == '__main__':
    main()
